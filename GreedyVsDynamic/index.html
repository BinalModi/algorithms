<html>
    <head>
        <link href="../style.css" rel="stylesheet" type="text/css"/>
        <title>
            Greed Versus Dynamism
        </title>
    </head>

    <body>

        <h1>
            Greed Versus Dynamism: When Can We Make the Greedy Choice?
        </h1>
            <p class="authors">
                Gene Callahan,
                Tandon School of Engineering,
                New York University
                <br />
                Robert P. Murphy,
                Free Market Institute,
                Texas Tech University
                <br />
                Salim Arfaoui,
                Department of Computer Science and Mathematics,
                St. Joseph's College, Brooklyn
            </p>

            <hr>

            <blockquote>
            Richard Bellman showed that a dynamic optimization problem in
            discrete time can be stated in a 
            recursive, step-by-step form known
            as backward induction by writing 
            down the relationship between the
            value function in one period and 
            the value function in the next period.
            -- <a
               href="https://en.wikipedia.org/wiki/Bellman_equation">Wikipedia</a>
            </blockquote>

            <p>
            When a greedy algorithm can be (correctly) used,
            we don't need to worry about the next period!
            We simply choose what is best for
            <i>this</i> period. This occurs when the entire opportunity cost for a
            choice is contained in the current period.
            </p>

            <p>
            On the other hand, when the opportunity cost spills over into
            future periods, we must resort to dynamic programming.
            </p>

            <p>
            Ferguson and Lim (2007) capture this idea in their distinction
            between static and dynamic consumption problems:
            </p>

            <blockquote> 
                In a static consumption problem the opportunity cost of
                spending an amount of money buy a unit of one commodity (and
                deriving the marginal utility associated with consuming one
                more unit of that commodity) is the largest extra utility would
                have derived from spending money some other on some other
                commodity. In a dynamic problem the opportunity cost of
                spending today is the largest extra lifetime utility we could
                have derived from saving the money and spending it at some
                point in the future.
            </blockquote>

            <p>
                In their terms, when we have a static consumption problem
                (i.e., the opportunity cost is confined to the current period),
                we can use a greedy algorithm. When the opportunity cost must be
                considered over future periods, we must use dynamic
                programming.
            </p>

            <p>
                This paper aims to show that, while the distinction between
                static and dynamic allocation problems, based on
                the periods in which the opportunity costs of a choice falls, is
                well-understood in economics, the idea is not as clear in
                computer science. And what's more, we suggest that the computer
                science literature, especially in pedagogy, could benefit from
                incorporating this distinction.
            </p>

            <p>
                But in the computer science literature the distinction is not
                as clerly set out:
            </p>

            <blockquote>
                Informally, a "greedy" optimization algorithm
                solves a global minimization or maximization problem
                by making a sequence of locally optimal decisions. A
                decision is "local" or "myopic" if it is based on
                partial information that does
                not include global knowledge about future
                consequences of current decisions
                (Heyman and Sobel, 1984); thus, the current
                decision, once made, might turn out
                to be nonoptimal. (Lew 2006, p. 621)
            </blockquote>

            <p>
                Lew later states:
            </p>

            <blockquote>
            While we lack a general procedure to determine whether or not a
            canonical greedy algorithm is optimal, no general procedure exists
            for noncanonical greedy algorithms either.
            </blockquote>

            <h2>
                Other material
            </h2>
                <ul>
                    <li>
                        <a href="biblio.html">
                        Bibliography
                        </a>
                    </li>
                    <li>
                        <a
                            href="https://pdfs.semanticscholar.org/dead/b452ffd9b2f90fd604e4fe5662ebdc2d2ee8.pdf">
                            A preliminary presentation trying to sort out when greedy
                            applies.
                        </a>
                        <br />
                        (This video was made just before the idea for this
                        paper was fully formulated.)
                    </li>
                    <li>
                    <a href="../DPVideo.html">
                    Dynamic programming video
                    </a>
                    </li>
                    <li>
                    <a href="https://en.wikipedia.org/wiki/Bellman_equation"> 
                    Bellman equation
                    </a>
                    </li>
                </ul>
    </body>
</html>
